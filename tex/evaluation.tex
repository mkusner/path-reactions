% !TEX root =  ../main.tex

%\subsection{Results and Evaluation}

\begin{table}[t]
 \begin{minipage}[l]{0.4\textwidth}
  \caption{Results when using \ourModel  for reaction mechanism prediction. Here we count a prediction as correct if the atom mapped action sequences predicted by our model match exactly those extracted from the USPTO dataset.}
  \label{table:mech-predict}
  \end{minipage}\hfill
 \begin{minipage}[r]{0.53\textwidth}
%  \centering
  \begin{tabular}{lllll}
    \toprule
    & \multicolumn{4}{c}{Accuracies (\%)}                   \\
    \cmidrule(r){2-5}
    Model Name & Top-1 & Top-2 & Top-3 & Top-5 \\
    \midrule
    \ourModelIR &  70.3 &  82.8 & 87.7 & 92.2    \\
    \ourModelR  &  77.8 &  89.2 & 92.4 & 94.7    \\
    \bottomrule
  \end{tabular}
  \end{minipage}
  \vspace{-0.25cm}
\end{table}

In our experiments we ultimately will consider two variants of the model: 
the first model \ourModelR  is exactly as defined in Section\ \ref{sec:model}, including all reagent information;
a second version we call \ourModelIR ignores the reagents when selecting the initial action (i.e.\ no context vector $\contextVect_\mathrm{reagent}$ is input into $\fInitial$), 
allowing us to gauge the importance of reagents in determining what reaction occurs.

%Having trained our model, 
One challenge is in forming a precise definition of what it means for to ``correctly'' predict the reaction outcome. 
Part of this relates to whether we are interested in  \emph{reaction mechanism prediction} or \emph{reaction product prediction}. %\todo{these should have been described by now using fig 1 but back check.} 
In this section we evaluate our model in each of these regimes in turn.
%Sampling from our model, or selecting high-probability candidates using beam search, yields

\subsection{Reaction Mechanism Prediction}

For mechanism prediction we are interested in making sure that we got the exact sequence of actions correct.
For instance, when forming a bond between two pairs of atoms we want to know which one of the atoms donated the electron pair needed to form the bond, even if the end result is the same. 
The representation of the reaction mechanism produced by our model is a sequence of atoms, detailing the path taken by the electrons in a series of alternating steps in which bonds are broken and formed; using the atom mapping from the USPTO dataset this takes the form of a series of integers.
%
%this then can take the form of a sequence of integers.
%Here in order to associate a fixed identity with each atom, these integers represent the ``atom mapped'' labels associated to each atom in the sequence.

The most straightforward approach then to evaluate our accuracy at predicting reaction mechanisms is to check whether the sequence of integers extracted from the raw data as described earlier
is an exact match with the sequence of integers output by \ourModel; the top-1, top-2, top-3, and top-5 accuracies evaluated in this manner are reported in Table \ref{table:mech-predict}.



\subsection{Reaction Product Prediction}
\label{sec:product-prediction}



\begin{table}[t]
\begin{minipage}[l]{0.42\textwidth}
  \caption{Results when using \ourModel  for reaction product prediction, following the product matching procedure in Section~\ref{sec:product-prediction}. 
The WLDN accuracy is computed using their evaluation code and pretrained model outputs on our test set.
We were unable to evaluate the Seq2Seq model on our test set, instead quoting their reported numbers with an asterisk.}
  \label{table:prod-predict}
  \end{minipage}\hfill
  \begin{minipage}[r]{0.53\textwidth}
%  \centering
  \begin{tabular}{lllll}
    \toprule
    & \multicolumn{4}{c}{Accuracies (\%)}                   \\
    \cmidrule(r){2-5}
    Model Name & Top-1 & Top-2 & Top-3 & Top-5 \\
    \midrule
    \ourModelIR &  78.2 & 87.7 & 91.5 & 94.4   \\
    \ourModelR  &  {\bf 87.0} & {\bf 92.6} & {\bf 94.5} & {\bf 95.9}    \\
    \bottomrule \toprule
    WLDN \citep{jin2017predicting} & 84.0  & 89.2 &  91.1 & 92.3 \\
    Seq2Seq \citep{schwaller2017found} & 80.3$^\star$ & 84.7$^\star$ & 86.2$^\star$ & 87.5$^\star$ \\
    \bottomrule
  \end{tabular}
  \end{minipage}
    \vspace{-0.25cm}
\end{table}


Reaction mechanism prediction is useful for ensuring that we formed the correct product in the {\em correct way}.
However, this can underestimate the model's actual predictive accuracy: 
although a single atom mapping is provided as part of the USPTO dataset, in general atom mappings are not unique; 
when a reactant contains some symmetries, then multiple different atom mappings are effectively equivalent.
Here this would manifest as multiple different sequences of integers which correspond to chemically identical electron paths. 
Figure 1 in the supplemental material shows an example of a reaction with many symmetries, where the mechanism may be correct despite a different atom sequence.
%\sout{An extreme example is a reaction in which one reactant is benzene, a molecule which is formed of six carbon atoms in a completely symmetric ring: while this would be present with a unique atom mapping in the dataset, any reaction path which includes one of these carbon atoms could equally well have selected any of the other five \todo{maybe toss in an inline figure with an example}.}

Recent machine learning approaches to {\em reaction product prediction} \citep{jin2017predicting,schwaller2017found}
have evaluated whether the major product reported in the test dataset matches predicted candidate products generated by their system, independent of mechanism.
In our case, the top-5 accuracy for a particular reaction may include multiple different electron paths that ultimately yield the same product molecule.

Identifying whether two product molecules are chemically the same is equivalent to solving a graph isomorphism over the atoms and bond types, comparing the output of our system to the product molecule.
To perform this comparison, we consider an electron path as a sequence of edits performed on the reactants graph, apply these edits to define a product graph, 
and then define a deterministic mapping from the edited graph to a canonical string representation.
This is done by first kekulizing the molecule, % \todo[]{proper noun or what?},
then applying the sequence of edits to the reactants graph,
setting explicit charges or hydrogen counts on the first and last atom in the electron path in order to satisfy valence constraints.
We then strip all atom map numbers from the graph.
If this graph corresponds to a valid product molecule, we can use RDKit to express the molecule in a canonical SMILES string format;
predicted electron paths which yield chemically infeasible products are considered failures.
We can then evaluate whether a predicted electron path matches the ground truth by a string comparison.

To use our model to produce a ranked list of predicted products, we compute the canonicalized product SMILES for each of the predictions found by beam search over electron paths, removing duplicates along the way. 
These product-level accuracies are reported in Table~\ref{table:prod-predict}.
For product prediction we compare with the state-of-the-art graph-based method \cite{jin2017predicting};
we use their evaluation code and pre-trained model\footnote{\url{https://github.com/wengong-jin/nips17-rexgen}},
re-evaluated on our extracted test set of elementary heterolytic reactions.
%We note their performance is slightly better on this test set than on the USPTO dataset as a whole.
We also trained a Seq2Seq baseline model following \cite{schwaller2017found};
unfortunately, with the hyperparameter settings described in the paper we were not able to reproduce their results.
As the authors have not released code or a trained model, we were unable to evaluate it on our test set, and instead quote their reported performance on a different USPTO test set for reference.
Overall, \ourModelR outperforms all other approaches on this metric, with 87\% top-1 accuracy and 95.9\% top-5 accuracy.
Omitting the reagents in \ourModelR degrades top-1 accuracy slightly, but maintains a high top-3 and top-5 accuracy,
suggesting that reagent information is necessary to provide context in disambiguating different plausible reaction paths.
\todo[]{say more here...?}



If the ultimate desired goal is to predict the product molecule rather than the electron path,
a benefit of our approach is the predicted electron paths then can serve as explanation. 
In this manner, when showing predicted products, we can list, alongside the maximum likelihood path, any other candidate paths that result in the same product. 
\todo[]{point to figure in supplement if there is one}

%For each predicted product molecule, there is at least one electron path generated by our model which produced it;
%whichever of these was highest-ranked by the beam search corresponds to the maximum likelihood path, 
%but we can also report the other candidate paths which would produce the sample output as alternative explanations.
%



%\highlight{MAYBE EXAMPLE IN APPENDIX FIGURE.}



