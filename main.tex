\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
\PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2017
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2017}

\usepackage{nips_2018}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2017}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\usepackage{hyperref}

\usepackage{amssymb}
\usepackage{amsmath}

% For citations
\usepackage{natbib}

% For figures
\usepackage{graphicx} % more modern
\usepackage{wrapfig}
%\usepackage{epsfig} % less modern
\usepackage{subfigure} 
\usepackage{multirow}
\usepackage{adjustbox}

\usepackage{listings}
\usepackage{textcomp}

% For assumptions
\usepackage{amsthm,amssymb,amsopn}
\newtheorem{assumption}{Assumption}
\newtheorem{define}{Definition}
\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}
\newtheorem{coro}{Corollary}
\newtheorem{condition}{Condition}
\usepackage{xspace}
\usepackage{bm}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}
\renewcommand{\algorithmiccomment}[1]{~~~~\textcolor{gray}{$\triangleright$\textit{#1}}}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\makeatletter
\makeatletter
\newcommand*{\da@rightarrow}{\mathchar"0\hexnumber@\symAMSa 4B }
\newcommand*{\da@leftarrow}{\mathchar"0\hexnumber@\symAMSa 4C }
\newcommand*{\xdashrightarrow}[2][]{%
  \mathrel{%
    \mathpalette{\da@xarrow{#1}{#2}{}\da@rightarrow{\,}{}}{}%
  }%
}
\newcommand{\xdashleftarrow}[2][]{%
  \mathrel{%
    \mathpalette{\da@xarrow{#1}{#2}\da@leftarrow{}{}{\,}}{}%
  }%
}
\newcommand*{\da@xarrow}[7]{%
  % #1: below
  % #2: above
  % #3: arrow left
  % #4: arrow right
  % #5: space left 
  % #6: space right
  % #7: math style 
  \sbox0{$\ifx#7\scriptstyle\scriptscriptstyle\else\scriptstyle\fi#5#1#6\m@th$}%
  \sbox2{$\ifx#7\scriptstyle\scriptscriptstyle\else\scriptstyle\fi#5#2#6\m@th$}%
  \sbox4{$#7\dabar@\m@th$}%
  \dimen@=\wd0 %
  \ifdim\wd2 >\dimen@
    \dimen@=\wd2 %   
  \fi
  \count@=2 %
  \def\da@bars{\dabar@\dabar@}%
  \@whiledim\count@\wd4<\dimen@\do{%
    \advance\count@\@ne
    \expandafter\def\expandafter\da@bars\expandafter{%
      \da@bars
      \dabar@ 
    }%
  }%  
  \mathrel{#3}%
  \mathrel{%   
    \mathop{\da@bars}\limits
    \ifx\\#1\\%
    \else
      _{\copy0}%
    \fi
    \ifx\\#2\\%
    \else
      ^{\copy2}%
    \fi
  }%   
  \mathrel{#4}%
}
\makeatother

% for striking out.
\usepackage[normalem]{ulem}

% for todos
\usepackage{xargs}                      % Use more than one optional parameter in a new commands
\usepackage[pdftex,dvipsnames]{xcolor}
%todos -- remove at end
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
\newcommand{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
\newcommand{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
\newcommand{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}
\newcommand{\improvement}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}

% quick-and-dirty TKTKTK
\newcommand{\highlight}[1]{\colorbox{yellow}{#1}}

\newcommand{\ourModel}{EPPM\xspace}
\newcommand{\ourModelIR}{EPPM-IR\xspace}
\newcommand{\ourModelR}{EPPM-R\xspace}

\title{Predicting Electron Paths}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  David S.~Hippocampus\thanks{Use footnote for providing further
    information about author (webpage, alternative
    address)---\emph{not} for acknowledging funding agencies.} \\
  Department of Computer Science\\
  Cranberry-Lemon University\\
  Pittsburgh, PA 15213 \\
  \texttt{hippo@cs.cranberry-lemon.edu} \\
  %% examples of more authors
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\input{tex/notation}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
The vast majority of chemical reactions can be described as the movement of pairs of electrons through a set of reactant molecules. 
As such, reactions are often described using `arrow-pushing' diagrams which show this movement as a sequence of arrows. 
We propose ElectronNet to learn these sequences directly from data.
Instead of predicting product molecules directly from reactant molecules in one-shot, learning a model of electron movement has the benefits of 
(a) being easy for chemists to interpret, 
(b) being able to incorporate the constraints of chemistry such as balanced atom counts each side, and 
(c) naturally encoding the sparsity of chemical reactions, which usually involve only a small number of atoms in the reactants.
Furthermore, we show that the model recovers basic knowledge of chemistry without being explicitly trained so.
% also it means the sides balance
\end{abstract}


\section{Introduction}
\input{tex/intro}



\section{Background}
\input{tex/background}



\begin{figure*}
\centering
\includegraphics[width=\textwidth]{reaction_diagram}
\caption{a) The reaction prediction problem: Given the reactants and reagents, predict the structure of the product.}
\end{figure*}

% KEY: separate assumptions from data processing
\input{tex/model}




 




% While this assigns probabilities to discrete actions this can be a function of continuous embeddings of molecules as above. 

% To learn $g_\theta$, one idea is to sample a path $\Pc$ and apply it to our initial set of molecules $\Mc_0$. Using the known deterministic function $f$ we can produce a final predicted set of molecules $\hat{\Mc}_T$. However, even if we have a loss function $\ell(\hat{\Mc}_T,\Mc_T)$ we cannot use REBAR or RELAX to compute $\frac{\partial \ell(\hat{\Mc}_T,\Mc_T)}{\partial \theta}$ because $f$ is not stochastic. Maybe it's possible to make $f$ stochastic, then maybe it is possible to apply REBAR or RELAX.

% Another idea is to learn $g_\theta$ via maximum likelihood. Specifically, $g_\theta$ assigns some probability to all possible paths, so we can adjust $\theta$ to make the paths that lead to $\Mc_T$ more likely and those that do not less likely. I believe an efficient way to do this is to roll out only a few paths to produce $\hat{\Mc}_T$ (i.e., using the valid path sampling method using Algorithm~\ref{algo:valid_path}) and then update $\theta$ via $\frac{\partial \ell(\hat{\Mc}_T,\Mc_T)}{\partial \theta}$. Maybe Monte Carlo Tree Search could be useful here? I need to read more about this. 

% \subsection{Notes}
% In general I haven't given as much thought to a stochastic model. This is because ultimately we don't really want to give a chemist a distribution over electron paths, they want to know an actual prediction of electron movements. One could argue that this distribution might be a proxy for reaction `energy', but I don't think we need to learn a distribution to get this. We could make Algorithm 1 stochastic by instead of selecting the closest atom in steps 6 and 12, we select an atom with Gaussian probability given by the Euclidean distance between atoms in $\Mc_t$ and the predicted action $\hat{\ab}$. It's not clear to me whether this is a better or worse proxy for reaction energy.

% The main question is whether it will be easier to learn a stochastic function or two deterministic functions that give realistic electron paths. I think this boils down to (a) can we sample enough roll-outs to get a peaky distribution, (b) will learning both $g$ and $f$ lead to too much approximation error.



% We propose to learn a function $g: \Mc \rightarrow \Pc$. 

% Because we do not know the true path $\Pc$, we can only receive a learning signal from the final predicted product molecules $\hat{\Mc}_T$ (compared to the true final molecules $\Mc_T$. This final predicted product is a deterministic (known) function $f$ of the initial molecules $\Mc_0$ and predicted actions $\hat{\Pc}$ (from $g$), as such $f(\Mc_0, \hat{\Pc}) = \hat{\Mc}_2, \ldots, \hat{\Mc}_T$.

% Ideally, we would like to learn the parameters of $g$, called $\theta$, to minimize the difference between the predicted final molecules $\hat{\Mc}_T$ and $\Mc_T$ (i.e., via some loss function $\ell$). However, we cannot resort to gradient-based techniques to learn $g$ because the inputs and outputs of $g$ are discrete objects, and the function $f$ producing $\hat{\Mc}_T$ is also discrete so the gradient $\frac{\partial \ell(\hat{\Mc}_T,\Mc_T)}{\partial \theta}$ does not exist. To solve this, we propose two types of models for this problem.

% \paragraph{Deterministic.}
% Instead, we assume we have continuous mappings from molecules $\Mc$ to vectors $\mb$ and paths $\Pc$ to matrices $\Pb$. We propose to learn continuous functions $g_\theta: \mb \rightarrow \Pb$ and $f_\phi: \mb, \Pb \rightarrow \mb, \ldots, \mb$. Then we can compute derivatives of a loss function $\ell(\hat{\mb}_T,\mb_T)$ with respect to parameters $\theta$ as follows. Let $\hat{\mb}_T = [f(\mb_1,g(\mb_1))]_T$. Then our gradient is $\frac{\partial \ell(\hat{\mb}_T,\mb_T)}{\partial \theta} = \frac{\partial \ell(\hat{\mb}_T,\mb_T)}{\partial f}\frac{\partial f}{\partial g}\frac{\partial g}{\partial \theta}$.

% Note that now, $f_\phi$ is unknown. So we propose to learn it given observed traces: $(\mb_1,\Pb,\mb_2,\ldots,\mb_T)$. For simplicity define $\Mb_{2:T} = [\mb_2,\ldots,\mb_T]$, and $f(\mb_1,\Pb) = \hat{\Mb}_{2:T}$. Then, given a loss function $l(\hat{\Mb}_{2:T},\Mb_{2:T})$ we can learn the parameters of $f$, called $\phi$ via the gradient $\frac{\partial l(\hat{\Mb}_{2:T},\Mb_{2:T})}{\partial \phi} = \frac{\partial l(\hat{\Mb}_{2:T},\Mb_{2:T})}{\partial f} \frac{\partial f}{\partial \phi}$.

% In order to ensure that $g_\theta$ produces paths $\hat{\Pb}$ that are valid (i.e., that alternately remove and add bonds) we propose to take a predicted path $\hat{\Pb}$ and map it to a valid path $\Pb^*$ as described in Algorithm~\ref{algo:valid_path}. Given a valid path, we propose a loss function $L(\hat{\Pb},\Pb^*)$ and learn $g_\theta$ to minimize this loss via $\frac{\partial L(\hat{\Pb},\Pb^*)}{\partial \theta} = \frac{\partial L(\hat{\Pb},\Pb^*)}{\partial g} \frac{\partial g}{\partial \theta}$.



% %another loss function 
% %Finally, one last appealing property of this model is that if similar molecules have similar continuous representations embeddings then the functions $g_\theta, f_\phi$ allow us to generalize to similar molecules we have not seen before.
% Function $f_\phi$ could be an RNN and $g_\theta$ could be a fully connected network. We could consider an alternative $g_\theta$ that is conditioned on previous states which could be an RNN. 



% \paragraph{Stochastic.}

%Given a learned distribution we could sample valid paths using Algorithm~\ref{algo:valid_path}. We could use a model similar to DRAW. Maybe it is possible to not learn $f$ and instead use a dynamic programming algorithm to update $g_\theta$. Otherwise, we could learn $f$ as a stochastic function over discrete states. In general I haven't given as much thought to a stochastic model.
%Note that this distribution is not Markov as we need to know if the previous two electron movement added or removed a bond, in order to determine whether we need to consider only existing bonds or not. We could use a model similar to DRAW and mask all samples so agree with these constraints.




% TODO:
% - write intuitive idea
% - formalize variables
% - wait a long time until writing objective
% - wait even longer to write optimization

\section{Experiments}

% describe USPTO dataset and preprocessing
\input{tex/dataset}

% having created dataset describe how trained and detailed model architecture.
\input{tex/training}

% describe issues with evaluation, results tables
\input{tex/evaluation}

\input{tex/qualitative}

\section{Discussion}



\bibliography{bibliography}
\bibliographystyle{plainnat}




% \begin{figure*}
% \centering
% \includegraphics[width=\textwidth]{rxn_example}
% \vspace{-3ex}
% \caption{Two example reactions and their electron paths. In reaction (a), the reaction starts from an existing bond between Lithium (atom 1) and Carbon (atom 2). In reaction (b) the reaction starts from a lone-pair of electrons on Nitrogen (atom 1), which we represent formally as a bond with itself.}
% \label{fig:example}
% \end{figure*}



\end{document}
